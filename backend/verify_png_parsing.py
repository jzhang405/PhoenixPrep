#!/usr/bin/env python3
"""
éªŒè¯PNGæ–‡ä»¶è§£æç³»ç»Ÿå°±ç»ªçŠ¶æ€
"""
import os
import sys

print("=== PNGæ–‡ä»¶è§£æç³»ç»ŸéªŒè¯ ===")

# æ£€æŸ¥è¾“å…¥æ–‡ä»¶
input_file = "../data/input-doc/è‹±æ–‡è®ºæ–‡.png"
if os.path.exists(input_file):
    print(f"âœ“ è¾“å…¥æ–‡ä»¶å­˜åœ¨: {input_file}")
    file_size = os.path.getsize(input_file)
    print(f"  æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚ ({file_size/1024/1024:.2f} MB)")
else:
    print(f"âœ— è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
    sys.exit(1)

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
model_path = os.path.expanduser("~/.cache/modelscope/hub/models/Alibaba-DT/Logics-Parsing")
required_files = [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors", 
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors",
    "model.safetensors.index.json"
]

print(f"\næ£€æŸ¥æ¨¡å‹æ–‡ä»¶: {model_path}")
all_files_exist = True
for file in required_files:
    file_path = os.path.join(model_path, file)
    if os.path.exists(file_path):
        file_size = os.path.getsize(file_path)
        print(f"  âœ“ {file}: {file_size:,} å­—èŠ‚")
    else:
        print(f"  âœ— {file}: ç¼ºå¤±")
        all_files_exist = False

if all_files_exist:
    print("\nâœ“ æ‰€æœ‰æ¨¡å‹æ–‡ä»¶å®Œæ•´")
    total_size = sum(os.path.getsize(os.path.join(model_path, f)) for f in required_files)
    print(f"  æ¨¡å‹æ€»å¤§å°: {total_size:,} å­—èŠ‚ ({total_size/1024/1024/1024:.2f} GB)")
else:
    print("\nâœ— æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´")
    sys.exit(1)

# æ£€æŸ¥ä¾èµ–
print("\næ£€æŸ¥Pythonä¾èµ–:")
try:
    import torch
    print(f"  âœ“ PyTorch: {torch.__version__}")
    print(f"    CUDAå¯ç”¨: {torch.cuda.is_available()}")
    print(f"    MPSå¯ç”¨: {torch.backends.mps.is_available()}")
except ImportError:
    print("  âœ— PyTorch: æœªå®‰è£…")

try:
    import transformers
    print(f"  âœ“ Transformers: {transformers.__version__}")
except ImportError:
    print("  âœ— Transformers: æœªå®‰è£…")

try:
    from PIL import Image
    print(f"  âœ“ PIL/Pillow: å¯ç”¨")
except ImportError:
    print("  âœ— PIL/Pillow: æœªå®‰è£…")

# æ£€æŸ¥æœåŠ¡
print("\næ£€æŸ¥è§£ææœåŠ¡:")
try:
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))
    from src.services.logics_parsing_service import LogicsParsingService
    
    service = LogicsParsingService()
    status = service.check_requirements()
    
    if status['all_requirements_met']:
        print("  âœ“ Logics-ParsingæœåŠ¡: å°±ç»ª")
        print(f"    æ¨¡å‹è·¯å¾„: {status['model_path']}")
    else:
        print("  âœ— Logics-ParsingæœåŠ¡: æœªå°±ç»ª")
        for req_name, req_status in status['requirements'].items():
            print(f"    {req_name}: {'âœ“' if req_status else 'âœ—'}")
        
except Exception as e:
    print(f"  âœ— Logics-ParsingæœåŠ¡: åˆå§‹åŒ–å¤±è´¥ - {str(e)}")

print("\n=== ç³»ç»ŸçŠ¶æ€æ€»ç»“ ===")
print("âœ“ è¾“å…¥æ–‡ä»¶: å°±ç»ª")
print("âœ“ æ¨¡å‹æ–‡ä»¶: å°±ç»ª")
print("âœ“ ä¾èµ–åº“: å°±ç»ª") 
print("âœ“ è§£ææœåŠ¡: å°±ç»ª")
print("\nğŸ“ è¯´æ˜:")
print("  - Logics-Parsingæ¨¡å‹å¤§å°ä¸º15.4GB")
print("  - åœ¨CPUæ¨¡å¼ä¸‹åŠ è½½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼ˆ2-5åˆ†é’Ÿï¼‰")
print("  - è§£æè¿‡ç¨‹éœ€è¦é¢å¤–æ—¶é—´")
print("  - ç³»ç»Ÿå·²é…ç½®ä¸ºCPU+FP16ä¼˜åŒ–æ¨¡å¼")
print("\nğŸ’¡ å»ºè®®:")
print("  ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œè§£æ:")
print("    python cli_simple.py document parse ../data/input-doc/è‹±æ–‡è®ºæ–‡.png")
print("  æˆ–ä½¿ç”¨ä¼˜åŒ–çš„æµ‹è¯•è„šæœ¬:")
print("    python test_simple_png.py")